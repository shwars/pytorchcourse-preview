{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Networks and MobileNet\n",
    "\n",
    "We have seen that complex networks require significant computational resources, such as GPU, for training, and also for fast inference. However, it turns out that a model with significanly smaller number of parameters in most cases can still be trained to perform resonably well. In other words, increase in the model complexity typically results in small (non-proportional) increase in the model performance.\n",
    "\n",
    "We have observed this in the beginning of the module when training MNIST digit classification. The accuracy of simple dense model was not significanly worse than that of a powerful CNN. Increasing the number of CNN layers and/or number of neurons in the classifier allowed us to gain a few percents of accuracy at most.\n",
    "\n",
    "This leads us to the idea that we can experiment with Lightweight network architectures in order to train faster models. This is especially important if we want to be able to execute our models on mobile devices.\n",
    "\n",
    "This module will rely on the Cats and Dogs dataset that we have downloaded in the previous unit. First we will make sure that the dataset is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import os\n",
    "\n",
    "from pytorchcv import train, display_dataset, train_long, load_cats_dogs_dataset, validate, common_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/kagglecatsanddogs_3367a.zip'):\n",
    "    !wget -P data -q http://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "\n",
    "dataset, train_loader, test_loader = load_cats_dogs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "\n",
    "In the previous unit, we have seen **ResNet** architecture for image classification. More lightweight analog of ResNet is **MobileNet**, which uses so-called *Inverted Residual Blocks*. Let's load pre-trained mobilenet and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNReLU(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vmuser/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the model to our dataset and make sure that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(281)\n"
     ]
    }
   ],
   "source": [
    "sample_image = dataset[0][0].unsqueeze(0)\n",
    "res = model(sample_image)\n",
    "print(res[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compare the number of parameters in MobileNet and full-scale ResNet model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using MobileNet for Transfer Learning\n",
    "\n",
    "Now let's perform the same transfer learning process as in previous unit, but using MobileNet. First of all, let's freeze all parameters of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in model.parameters():\n",
    "    x.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, replace the final classifier. We also transfer the model to our default training device (GPU or CPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 122, 122]             864\n",
      "       BatchNorm2d-2         [-1, 32, 122, 122]              64\n",
      "             ReLU6-3         [-1, 32, 122, 122]               0\n",
      "            Conv2d-4         [-1, 32, 122, 122]             288\n",
      "       BatchNorm2d-5         [-1, 32, 122, 122]              64\n",
      "             ReLU6-6         [-1, 32, 122, 122]               0\n",
      "            Conv2d-7         [-1, 16, 122, 122]             512\n",
      "       BatchNorm2d-8         [-1, 16, 122, 122]              32\n",
      "  InvertedResidual-9         [-1, 16, 122, 122]               0\n",
      "           Conv2d-10         [-1, 96, 122, 122]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 122, 122]             192\n",
      "            ReLU6-12         [-1, 96, 122, 122]               0\n",
      "           Conv2d-13           [-1, 96, 61, 61]             864\n",
      "      BatchNorm2d-14           [-1, 96, 61, 61]             192\n",
      "            ReLU6-15           [-1, 96, 61, 61]               0\n",
      "           Conv2d-16           [-1, 24, 61, 61]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-18           [-1, 24, 61, 61]               0\n",
      "           Conv2d-19          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 61, 61]             288\n",
      "            ReLU6-21          [-1, 144, 61, 61]               0\n",
      "           Conv2d-22          [-1, 144, 61, 61]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 61, 61]             288\n",
      "            ReLU6-24          [-1, 144, 61, 61]               0\n",
      "           Conv2d-25           [-1, 24, 61, 61]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-27           [-1, 24, 61, 61]               0\n",
      "           Conv2d-28          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 61, 61]             288\n",
      "            ReLU6-30          [-1, 144, 61, 61]               0\n",
      "           Conv2d-31          [-1, 144, 31, 31]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 31, 31]             288\n",
      "            ReLU6-33          [-1, 144, 31, 31]               0\n",
      "           Conv2d-34           [-1, 32, 31, 31]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-36           [-1, 32, 31, 31]               0\n",
      "           Conv2d-37          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 31, 31]             384\n",
      "            ReLU6-39          [-1, 192, 31, 31]               0\n",
      "           Conv2d-40          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 31, 31]             384\n",
      "            ReLU6-42          [-1, 192, 31, 31]               0\n",
      "           Conv2d-43           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-45           [-1, 32, 31, 31]               0\n",
      "           Conv2d-46          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 31, 31]             384\n",
      "            ReLU6-48          [-1, 192, 31, 31]               0\n",
      "           Conv2d-49          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 31, 31]             384\n",
      "            ReLU6-51          [-1, 192, 31, 31]               0\n",
      "           Conv2d-52           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-54           [-1, 32, 31, 31]               0\n",
      "           Conv2d-55          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 31, 31]             384\n",
      "            ReLU6-57          [-1, 192, 31, 31]               0\n",
      "           Conv2d-58          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 16, 16]             384\n",
      "            ReLU6-60          [-1, 192, 16, 16]               0\n",
      "           Conv2d-61           [-1, 64, 16, 16]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-63           [-1, 64, 16, 16]               0\n",
      "           Conv2d-64          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 16, 16]             768\n",
      "            ReLU6-66          [-1, 384, 16, 16]               0\n",
      "           Conv2d-67          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 16, 16]             768\n",
      "            ReLU6-69          [-1, 384, 16, 16]               0\n",
      "           Conv2d-70           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-72           [-1, 64, 16, 16]               0\n",
      "           Conv2d-73          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 16, 16]             768\n",
      "            ReLU6-75          [-1, 384, 16, 16]               0\n",
      "           Conv2d-76          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 16, 16]             768\n",
      "            ReLU6-78          [-1, 384, 16, 16]               0\n",
      "           Conv2d-79           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-81           [-1, 64, 16, 16]               0\n",
      "           Conv2d-82          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 16, 16]             768\n",
      "            ReLU6-84          [-1, 384, 16, 16]               0\n",
      "           Conv2d-85          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 16, 16]             768\n",
      "            ReLU6-87          [-1, 384, 16, 16]               0\n",
      "           Conv2d-88           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-90           [-1, 64, 16, 16]               0\n",
      "           Conv2d-91          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 16, 16]             768\n",
      "            ReLU6-93          [-1, 384, 16, 16]               0\n",
      "           Conv2d-94          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 16, 16]             768\n",
      "            ReLU6-96          [-1, 384, 16, 16]               0\n",
      "           Conv2d-97           [-1, 96, 16, 16]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 16, 16]             192\n",
      " InvertedResidual-99           [-1, 96, 16, 16]               0\n",
      "          Conv2d-100          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-102          [-1, 576, 16, 16]               0\n",
      "          Conv2d-103          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-105          [-1, 576, 16, 16]               0\n",
      "          Conv2d-106           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-108           [-1, 96, 16, 16]               0\n",
      "          Conv2d-109          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-111          [-1, 576, 16, 16]               0\n",
      "          Conv2d-112          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-114          [-1, 576, 16, 16]               0\n",
      "          Conv2d-115           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-117           [-1, 96, 16, 16]               0\n",
      "          Conv2d-118          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-120          [-1, 576, 16, 16]               0\n",
      "          Conv2d-121            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-123            [-1, 576, 8, 8]               0\n",
      "          Conv2d-124            [-1, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-126            [-1, 160, 8, 8]               0\n",
      "          Conv2d-127            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-129            [-1, 960, 8, 8]               0\n",
      "          Conv2d-130            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-132            [-1, 960, 8, 8]               0\n",
      "          Conv2d-133            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-135            [-1, 160, 8, 8]               0\n",
      "          Conv2d-136            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-138            [-1, 960, 8, 8]               0\n",
      "          Conv2d-139            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-141            [-1, 960, 8, 8]               0\n",
      "          Conv2d-142            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-144            [-1, 160, 8, 8]               0\n",
      "          Conv2d-145            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-147            [-1, 960, 8, 8]               0\n",
      "          Conv2d-148            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-150            [-1, 960, 8, 8]               0\n",
      "          Conv2d-151            [-1, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-153            [-1, 320, 8, 8]               0\n",
      "          Conv2d-154           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 8, 8]           2,560\n",
      "           ReLU6-156           [-1, 1280, 8, 8]               0\n",
      "          Linear-157                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 2,226,434\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,223,872\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 186.92\n",
      "Params size (MB): 8.49\n",
      "Estimated Total Size (MB): 196.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.classifier = nn.Linear(1280,2)\n",
    "model = model.to(device)\n",
    "summary(model,input_size=(3,244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the actual training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, minibatch 0: train acc = 1.0, train loss = 0.00018727575661614537\n",
      "Epoch 0, minibatch 90: train acc = 0.9495192307692307, train loss = 0.006199962490207546\n",
      "Epoch 0, minibatch 180: train acc = 0.9526933701657458, train loss = 0.006265106122138092\n",
      "Epoch 0, minibatch 270: train acc = 0.9556042435424354, train loss = 0.005903947397351705\n",
      "Epoch 0, minibatch 360: train acc = 0.9552458448753463, train loss = 0.006147158773321854\n",
      "Epoch 0, minibatch 450: train acc = 0.9548226164079823, train loss = 0.0062902259192287\n",
      "Epoch 0, minibatch 540: train acc = 0.9539625693160814, train loss = 0.006862575597992225\n",
      "Epoch 0 done, validation acc = 0.97695, validation loss = 0.0037557861328125\n"
     ]
    }
   ],
   "source": [
    "train_long(model,train_loader,test_loader,loss_fn=torch.nn.CrossEntropyLoss(),epochs=1,print_freq=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway\n",
    "\n",
    "Notice that MobileNet results in almost the same accuracy as VGG-16, and just slightly lower than full-scale ResNet. \n",
    "\n",
    "The main advantage of small models, such as MobileNet or ResNet-18 is that they can be used on mobile devices. [Here](https://pytorch.org/mobile/android/) is official example of using ResNet-18 on Android device, and [here](https://heartbeat.fritz.ai/pytorch-mobile-image-classification-on-android-5c0cfb774c5b) is similar example using MobileNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}